ham.tdm <- get.tdm(all.ham)
ham.matrix <- as.matrix( ham.tdm)
ham.counts <- rowSums( ham.matrix)
ham.df <- data.frame(cbind( names(ham.counts),
ham.matrix <- as.matrix( ham.tdm)
)
)
ham.matrix <- as.matrix( ham.tdm)
library('tm')
library('ggplot2')
spam.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data","spam/")
spam2.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data", "spam_2/")
easyham.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data", "easy_ham/")
easyham2.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data", "easy_ham_2/")
hardham.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data", "hard_ham/")
hardham2.path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data", "hard_ham_2/")
get.msg <- function(path)
{
con <- file(path, open = "rt", encoding = "latin1") #rt模式表示read as text,这句没有似乎也可以
text <- readLines(con) #读入的每一行是向量的一个元素
# The message always begins after the first full line break
msg <- text[ which(text != "")] #去掉空行
close(con)
#browser()
return(paste(msg, collapse = "\n")) #return在函数里就是用于返回，不用再赋值了
}
get.tdm <- function( doc.vec) {
doc.corpus <- Corpus( VectorSource(doc.vec))
control <- list( stopwords = T, removePunctuation = T,
removeNumbers = T, minDocFreq=2)
doc.dtm <- TermDocumentMatrix( doc.corpus, control)
return( doc.dtm)
}
ham.docs <- dir(easyham.path)
ham.docs <-ham.docs[which(ham.docs!="cmds")]
all.ham <- sapply( ham.docs,
function(p)  get.msg(paste(easyham.path,p,sep="")))
ham.tdm <- get.tdm(all.ham)
ham.matrix <- as.matrix( ham.tdm)
ham.counts <- rowSums( ham.matrix)
ham.df <- data.frame(cbind( names(ham.counts),
as.numeric(ham.counts)), stringsAsFactors= F)
names(ham.df) <- c("term", "frequency")
spam.df$frequency <- as.numeric( spam.df$frequency)
ham.tdm <- get.tdm(all.ham[1:500])
ham.matrix <- as.matrix( ham.tdm)
ham.counts <- rowSums( ham.matrix)
ham.df <- data.frame(cbind( names(ham.counts),
as.numeric(ham.counts)), stringsAsFactors= F)
names(ham.df) <- c("term", "frequency")
ham.df$frequency <- as.numeric( ham.df$frequency)
ham.occurrence <- sapply( 1: nrow(ham.matrix),
function(i) { length(which(ham.matrix[i,] >0))/ncol(ham.matrix)}) #有词的文档数
ham.density <- ham.df$frequency/sum(ham.df$frequency)
ham.df <- transform( ham.df, density=ham.density, occurrence = ham.occurrence)
head( ham.df[ with(ham.df, order( -occurrence)),]) ##这个用法犀利
ages <- read.csv("D:/github/2014_book_ML_for_Hackers/05-Regression/data/longevity.csv")
library(ggplot2)
ggplot( ages, aes( x= AgeAtDeath, fill = factor(Smokers))) + geom_density() + facet_grid(Smokes ~.)
View(ages)
ggplot( ages, aes( x= AgeAtDeath, fill = factor(Smokers))) + geom_density() + facet_grid(Smoke ~.)
ggplot( ages, aes( x= AgeAtDeath, fill = factor(Smokes))) + geom_density() + facet_grid(Smoke ~.)
ggplot( ages, aes( x= AgeAtDeath, fill = factor(Smokes))) + geom_density() + facet_grid(Smokes ~.)
View(ages)
View(ages)
top.1000.sites <- read.csv("D:/github/2014_book_ML_for_Hackers/05-Regression/data/top_1000_sites.tsv",
sep='\t', stringsAsFactors = F)
ggplot( top.1000.sites, aes( x = PageViews, y = UniqueVisitors))+geom_point()
ggplot( top.1000.sites, aes( x = log( PageViews), y = UniqueVisitors))+geom_point()
lm.fit <- lm( log(PageViews)~log(UniqueVisitors), data=top.1000.sites)
summary(lm.fit)
G <- matrix( c( 0, .5 , .5 , 0, .5, .25, 0,0,0,0, .25, 0,0,1,.5, .25, .5, .5, 0,0,.25,0,0,0,0),
ncol=5)
View(G)
G <- matrix( c( 0, .5 , .5 , 0, .5, .25, 0,0,0,0, .25, 0,0,1,.5, .25, .5, .5, 0,0,.25,0,0,0,0),
ncol=5, byrow=T)
View(G)
View(G)
colSums(G)
rowSums(G)
eigen(G)
)
p <- c(1,1,1,1 )
q <- c(1,1,1,1 )
G * q
G %*% q
q <- c(1,1,1,1,1)
G %*% q
l <- G %*% q
q-l
var( q-l )
crossprod( q-l )
q <- c(1,1,1,1,1)
l <- G %*% q
while ( corssprod( q-l) > 0.001) {
q <- l
l <- G %*% q
}
while ( crossprod( q-l) > 0.001) {
q <- l
l <- G %*% q
}
while ( crossprod( q-l) > 0.00001) {
q <- l
l <- G %*% q
}
l
rowSums(G)
matrix( rep(1,25), ncol =5)
matrix( rep(1,25), ncol =5) * .15
s = matrix(c(0,1/4,1/4,1/4,1/4, 1/2,0,0,1/2,0,1/2,0,0,1/2,0,0,0,1,0,0,1/2,0,1/2,0,0),5,5)
G = a*s+(1-a)*matrix(rep(1,25),5)/n
q = matrix(c(1,1,1,1,1))
while(i>0){
q = G %*% q
i <- i - 1
}
q
install.packages("arules")
library("rJava")
.jinit(classpath="MINE.jar")
MINE <- function (
input.filename,
style=c("master.variable", "all.pairs", "adjacent.pairs", "pairs.between", "one.pair"),
var1.id=NA,
var2.id=NA,
required.common.vals.fraction=0,
max.num.boxes.exponent=0.6,
notify.wait=100,
num.clumps.factor=15,
debug.level=0,
gc.wait=Inf,
job.id
) {
printHeader()
params <- getParams(input.filename, style, var1.id, var2.id, required.common.vals.fraction, max.num.boxes.exponent, notify.wait, num.clumps.factor, debug.level, gc.wait, job.id)
# run the analysis
cat("reading in dataset...\n")
flush.console()
dataset <- .jnew("data/Dataset",
params$inputfile,
params$analysisParams$mineParams$debug)
cat("done.\n")
flush.console()
doAnalysis(dataset, params)
}
###########################################
# rMINE - runs MINE on an R matrix.
#  all parameters are as in MINE, except
#  that the name of the results file will
#  begin with output.prefix rather than
#  the name of the input file (since there
#  is no input file).
#
#  MINE assumes that each row of the
#  supplied matrix is a variable, and each
#  column is a record.
#
# EXAMPLE:
#  rMINE(matrix(1:10,2),"matrix",0)
#   will run MINE on matrix(1:10,2),
#   assuming that each of the two rows
#   in the matrix is a variable.
###########################################
rMINE <- function (
data,
output.prefix,
style=c("master.variable", "all.pairs", "adjacent.pairs", "pairs.between", "one.pair"),
var1.id=NA,
var2.id=NA,
required.common.vals.fraction=0,
max.num.boxes.exponent=0.6,
notify.wait=100,
num.clumps.factor=15,
debug.level=0,
gc.wait=Inf,
job.id
) {
printHeader()
if(missing(output.prefix))
stop("you must specify output.prefix so that I'll know what to name the output file!")
params <- getParams(output.prefix, style, var1.id, var2.id, required.common.vals.fraction, max.num.boxes.exponent, notify.wait, num.clumps.factor, debug.level, gc.wait, job.id)
# run the analysis
cat("reading in dataset...\n")
flush.console()
data <- .jarray(data, dispatch=TRUE)
dataset <- .jnew("data/Dataset",
data, params$analysisParams$mineParams$debug)
cat("done.\n")
flush.console()
doAnalysis(dataset, params)
}
printHeader <- function () {
# print header
cat(J("main/Analyze")$header())
cat("\n\n")
flush.console()
}
getParams <- function(
input.filename,
style=c("master.variable", "all.pairs", "adjacent.pairs", "pairs.between", "one.pair"),
var1.id=NA,
var2.id=NA,
required.common.vals.fraction=0,
max.num.boxes.exponent=0.6,
notify.wait=100,
num.clumps.factor=15,
debug.level=0,
gc.wait=Inf,
job.id
) {
if (gc.wait==Inf) gc.wait <- J("java.lang.Integer")$MAX_VALUE
else gc.wait <- as.integer(gc.wait)
# create parameters object
if(missing(job.id)) {
args <- .jarray(c(
input.filename,
style,
var1.id,
var2.id,
paste("cv=", required.common.vals.fraction, sep = ""),
paste("exp=", max.num.boxes.exponent, sep = ""),
paste("notify=", notify.wait, sep = ""),
paste("c=", num.clumps.factor, sep = ""),
paste("d=", debug.level, sep = ""),
paste("gc=", gc.wait, sep = "")
))
} else {
args <- .jarray(c(
input.filename,
style,
var1.id,
var2.id,
paste("cv=", required.common.vals.fraction, sep = ""),
paste("exp=", max.num.boxes.exponent, sep = ""),
paste("notify=", notify.wait, sep = ""),
paste("c=", num.clumps.factor, sep = ""),
paste("d=", debug.level, sep = ""),
paste("gc=", gc.wait, sep = ""),
paste("id=", job.id, sep = "")
))
}
params <- .jnew("main/JobParameters", args)
flush.console()
#confirm parameters for user
cat(params$toString())
cat("\n")
flush.console()
params
}
doAnalysis <- function (dataset, params) {
toAnalyze <- .jnew("analysis/VarPairQueue", dataset)
params$analysisStyle$addVarPairsTo(toAnalyze, dataset$numVariables())
a <- .jnew("analysis/Analysis", dataset, toAnalyze)
cat("Analyzing...\n")
flush.console()
while(! a$varPairQueue()$isEmpty()) {
# print a status update
statusUpdate <- paste(a$numResults() + 1, " calculating: ", a$varPairQueue()$peek()$var1$name(), " vs ", a$varPairQueue()$peek()$var2$name(), "...\n", sep="")
cat(statusUpdate)
flush.console()
# create a file containing the status update (for use when running on a cluster)
write(statusUpdate, file=params$statusFileName())
# analyze some more pairs
a$analyzePairs(J("analysis.results/BriefResult")$class,
params$analysisParams,
params$notifyWait)
}
cat(paste(a$numResults(), " variable pairs analyzed.\n", "Sorting results in descending order...\n", sep=""))
flush.console()
results <- a$getSortedResults()
cat("done. printing results\n")
flush.console()
#print the results
repeat {
if(J("main/Analyze")$printResults(results, params)) {
break
}
else {
n <- readline("writing results to output file failed. Perhaps it is locked in some way. Enter 1 to try again, 0 otherwise: ")
if(n == 0) break
}
}
cat("Analysis finished. See file \"")
cat(params$resultsFileName())
cat("\" for output\n")
}
WHO <- read.csv("D:/github/dataguru_learningR/homework/WHO.csv")
View(WHO)
??MINE
rMINE(WHO, trytry, "one.pair", 1, 2, jobid=1)
rMINE(WHO, trytry, "one.pair", 1, 2, job.id=1)
??readLines
path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data/easy_ham")
readLines( path )
path <- file.path("D:/github/2014_book_ML_for_Hackers/03-Classification/data/easy_ham/")
readLines( path )
ham.docs <- dir(path)
list <- sapply( ( paste( path, ham.docs, sep="")), read.csv)
path <- file.path("D:/百度云同步盘/data/20130722 999salescv")
ham.docs <- dir(path)
list <- sapply( ( paste( path, ham.docs, sep="")), read.csv)
path <- file.path("D:/百度云同步盘/data/20130722 999salescv/")
ham.docs <- dir(path)
list <- sapply( ( paste( path, ham.docs, sep="")), read.csv)
list[[1]]
rm( ham.doc, list, path)
rm( ham.docs, list, path)
seq(3)
seq()
seq
??seq
seq(1,3,by=1)
rMINE(WHO, trytry, "one.pair", 1, 2, job.id=1)
MINE(WHO, trytry, "one.pair", 1, 2, job.id=1)
MINE("example.csv","all.pairs")
MINE(WHO, trytry, "one.pair", 1, 2, job.id=1)
library('ggplot2')
set.seed(1)
x <- seq(-10, 10, by = 0.01)
y <- 1 - x ^ 2 + rnorm(length(x), 0, 5)
ggplot(data.frame(X = x, Y = y), aes(x = X, y = Y)) +
geom_point() +
geom_smooth(se = FALSE)
x.squared <- x ^ 2
ggplot(data.frame(XSquared = x.squared, Y = y), aes(x = XSquared, y = Y)) +
geom_point() +
geom_smooth(method = 'lm', se = FALSE)
summary(lm(y ~ x))$r.squared
summary(lm(y ~ x.squared))$r.squared
summary(lm(y ~ x))$r.squared
summary(lm(y ~ x.squared))$r.squared
set.seed(1)
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
df <- data.frame(X = x, Y = y)
ggplot(df, aes(x = X, y = Y)) +
geom_point()
summary(lm(Y ~ X, data = df))
ggplot(data.frame(X = x, Y = y), aes(x = X, y = Y)) +
geom_point() +
geom_smooth(method = 'lm', se = FALSE)
df <- transform(df, X2 = X ^ 2)
df <- transform(df, X3 = X ^ 3)
summary(lm(Y ~ X + X2 + X3, data = df))
df <- transform(df, X4 = X ^ 4)
df <- transform(df, X5 = X ^ 5)
df <- transform(df, X6 = X ^ 6)
df <- transform(df, X7 = X ^ 7)
df <- transform(df, X8 = X ^ 8)
df <- transform(df, X9 = X ^ 9)
df <- transform(df, X10 = X ^ 10)
df <- transform(df, X11 = X ^ 11)
df <- transform(df, X12 = X ^ 12)
df <- transform(df, X13 = X ^ 13)
df <- transform(df, X14 = X ^ 14)
df <- transform(df, X15 = X ^ 15)
summary(lm(Y ~ X + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14,
data = df))
summary(lm(Y ~ poly(X, degree = 14), data = df))
poly.fit <- lm(Y ~ poly(X, degree = 1), data = df)
df <- transform(df, PredictedY = predict(poly.fit))
ggplot(df, aes(x = X, y = PredictedY)) +
geom_point() +
geom_line()
poly.fit <- lm(Y ~ poly(X, degree = 3), data = df)
df <- transform(df, PredictedY = predict(poly.fit))
ggplot(df, aes(x = X, y = PredictedY)) +
geom_point() +
geom_line()
poly.fit <- lm(Y ~ poly(X, degree = 5), data = df)
df <- transform(df, PredictedY = predict(poly.fit))
ggplot(df, aes(x = X, y = PredictedY)) +
geom_point() +
geom_line()
poly.fit <- lm(Y ~ poly(X, degree = 25), data = df)
df <- transform(df, PredictedY = predict(poly.fit))
ggplot(df, aes(x = X, y = PredictedY)) +
geom_point() +
geom_line()
# Twelfth code snippet
set.seed(1)
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
# Thirteenth code snippet
n <- length(x)
indices <- sort(sample(1:n, round(0.5 * n)))
training.x <- x[indices]
training.y <- y[indices]
test.x <- x[-indices]
test.y <- y[-indices]
training.df <- data.frame(X = training.x, Y = training.y)
test.df <- data.frame(X = test.x, Y = test.y)
# Fourteenth code snippet
rmse <- function(y, h)
{
return(sqrt(mean((y - h) ^ 2)))
}
# Fifteenth code snippet
performance <- data.frame()
for (d in 1:12)
{
poly.fit <- lm(Y ~ poly(X, degree = d), data = training.df)
performance <- rbind(performance,
data.frame(Degree = d,
Data = 'Training',
RMSE = rmse(training.y, predict(poly.fit))))
performance <- rbind(performance,
data.frame(Degree = d,
Data = 'Test',
RMSE = rmse(test.y, predict(poly.fit,
newdata = test.df))))
}
ggplot(performance, aes(x = Degree, y = RMSE, linetype = Data)) +
geom_point() +
geom_line()
# Seventeenth code snippet
lm.fit <- lm(y ~ x)
model.complexity <- sum(coef(lm.fit) ^ 2)
# Eighteenth code snippet
lm.fit <- lm(y ~ x)
l2.model.complexity <- sum(coef(lm.fit) ^ 2)
l1.model.complexity <- sum(abs(coef(lm.fit)))
# Ninteenth code snippet
set.seed(1)
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
# Twentieth code snippet
x <- as.matrix(cbind(x,rev(x)))
library('glmnet')
install.packages("glmnet")
library('glmnet')
glmnet(x, y)
set.seed(1)
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
n <- length(x)
indices <- sort(sample(1:n, round(0.5 * n)))
training.x <- x[indices]
training.y <- y[indices]
test.x <- x[-indices]
test.y <- y[-indices]
df <- data.frame(X = x, Y = y)
training.df <- data.frame(X = training.x, Y = training.y)
test.df <- data.frame(X = test.x, Y = test.y)
rmse <- function(y, h)
{
return(sqrt(mean((y - h) ^ 2)))
}
# Twenty-second code snippet
library('glmnet')
glmnet.fit <- with(training.df, glmnet(poly(X, degree = 10), Y))
lambdas <- glmnet.fit$lambda
performance <- data.frame()
for (lambda in lambdas)
{
performance <- rbind(performance,
data.frame(Lambda = lambda,
RMSE = rmse(test.y,
with(test.df,
predict(glmnet.fit,
poly(X, degree = 10),
s = lambda)))))
}
# Twenty-third code snippet
ggplot(performance, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line()
# Alternative plot not shown in the book.
ggplot(performance, aes(x = Lambda, y = RMSE)) +
geom_point() +
geom_line() +
scale_x_log10()
# Twenty-fourth code snippet
best.lambda <- with(performance, Lambda[which(RMSE == min(RMSE))])
iris
data(iris)
names(iris)
ld = lda( iris$Species ~ iris$Sepal.Length + iris$Sepal.Width + iris$Petal.Length + iris$Petal.width )
library(MASS)
ld = lda( iris$Species ~ iris$Sepal.Length + iris$Sepal.Width + iris$Petal.Length + iris$Petal.width )
View(iris)
ld = lda( iris$Species ~ iris$Sepal.Length + iris$Sepal.Width + iris$Petal.Length + iris$Petal.Width )
ld
z <- predict(ld)
z
??predict
z$class
z <- predict(ld , data=iris[,-5])
z$class
z$class
cbind( z$class, iris[,5])
table( z$class, iris[,5])
str(z)
t_alibaba_data <- read.csv("C:/Users/Administrator/Desktop/t_alibaba_data.csv")
View(t_alibaba_data)
head(t_alibaba_data)
odata <- read.csv("t_alibaba_data.csv")
setwd("D:\github\statistic_model\2014_ali_bigdata")
setwd("D:/github/statistic_model/2014_ali_bigdata")
odata <- read.csv("t_alibaba_data.csv")
odata <- read.csv("t_alibaba_data.csv")
head(odata)
library(sqldf)
install.packages("sqldf")
library(sqldf)
names(odata)
sqldf(" select count(distinct(user_id_)) from odata")
sqldf(" select count(distinct(user_id)) from odata")
sqldf(" select count(distinct(brand_id)) from odata")
sqldf(" select count(distinct(visit_datetime)) from odata")
summary(odata)
